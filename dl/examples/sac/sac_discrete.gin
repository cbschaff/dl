# Hyperparameters from Soft Actor Critic: https://arxiv.org/abs/1812.05905
import dl.examples.sac

train.algorithm = @SAC
train.maxt = 100000
train.seed = 0
train.eval = True
train.eval_period = 10000
train.save_period = 10000
train.maxseconds = None

SAC.env_fn = @make_env
SAC.policy_fn = @policy_fn_discrete
SAC.qf_fn = @qf_fn_discrete
SAC.vf_fn = @vf_fn
SAC.nenv = 1
SAC.eval_num_episodes = 20
SAC.record_num_episodes = 1
SAC.buffer_size = 10000
SAC.frame_stack = 1
SAC.learning_starts = 5000
SAC.update_period = 1
SAC.gpu = True
SAC.optimizer = @optim.Adam
SAC.batch_size = 128
SAC.policy_lr = 3e-4
SAC.qf_lr = 3e-4
SAC.vf_lr = 3e-4
SAC.policy_mean_reg_weight = 1e-3
SAC.gamma = 0.99
SAC.target_update_period = 1
SAC.policy_update_period = 1
SAC.target_smoothing_coef = 0.001
SAC.automatic_entropy_tuning = True
SAC.reparameterization_trick = False
SAC.target_entropy = None
SAC.reward_scale = 1
SAC.log_period = 100

Checkpointer.ckpt_period = 10000

optim.Adam.betas = (0.9, 0.999)

make_env.env_id = "LunarLander-v2"
make_env.norm_observations = True

VecObsNormWrapper.steps = 10000
VecObsNormWrapper.mean = None
VecObsNormWrapper.std = None
VecObsNormWrapper.eps = 1e-2
VecObsNormWrapper.log = True
VecObsNormWrapper.log_prob = 0.01
